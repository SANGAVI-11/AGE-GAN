{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing UTK Face Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 23709\n",
      "Image in A: 7134 and B: 7134\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_dir = r'images\\utkcropped'\n",
    "output_dir = r'images\\Processed'\n",
    "\n",
    "image_names = [x for x in os.listdir(data_dir) if x.endswith('.jpg')]\n",
    "print(f\"Total images found: {len(image_names)}\")\n",
    "\n",
    "ages = [int(x.split('_')[0]) for x in image_names]\n",
    "\n",
    "ages_to_keep_a = [x for x in range(18, 29)]\n",
    "ages_to_keep_b = [x for x in range(40, 120)]\n",
    "\n",
    "domainA, domainB = [], []\n",
    "for image_name, age in zip(image_names, ages):\n",
    "    if age in ages_to_keep_a:\n",
    "        domainA.append(image_name)\n",
    "    elif age in ages_to_keep_b:\n",
    "        domainB.append(image_name)\n",
    "\n",
    "N = min(len(domainA), len(domainB))\n",
    "domainA = domainA[:N]\n",
    "domainB = domainB[:N]\n",
    "\n",
    "print(f\"Image in A: {len(domainA)} and B: {len(domainB)}\")\n",
    "\n",
    "domainA_dir = os.path.join(output_dir, 'trainA')\n",
    "domainB_dir = os.path.join(output_dir, 'trainB')\n",
    "\n",
    "os.makedirs(domainA_dir, exist_ok=True)\n",
    "os.makedirs(domainB_dir, exist_ok=True)\n",
    "\n",
    "for imageA, imageB in zip(domainA, domainB):\n",
    "    shutil.copy(os.path.join(data_dir, imageA), os.path.join(domainA_dir, imageA))\n",
    "    shutil.copy(os.path.join(data_dir, imageB), os.path.join(domainB_dir, imageB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domainA_dir': 'C:\\\\Users\\\\ameen\\\\Documents\\\\AMRITA\\\\7th sem\\\\Project\\\\Code\\\\Fast-AgingGAN-master\\\\images\\\\Processed\\\\trainA', 'domainB_dir': 'C:\\\\Users\\\\ameen\\\\Documents\\\\AMRITA\\\\7th sem\\\\Project\\\\Code\\\\Fast-AgingGAN-master\\\\images\\\\Processed\\\\trainB', 'ngf': 32, 'ndf': 32, 'n_blocks': 9, 'adv_weight': 2, 'cycle_weight': 10, 'identity_weight': 7, 'lr': 0.0001, 'weight_decay': 0.0001, 'img_size': 256, 'batch_size': 3, 'num_workers': 4, 'epochs': 100, 'augment_rotation': 80, 'gpus': [1]}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Training with multiple optimizers is only supported with manual optimization. Remove the `optimizer_idx` argument from `training_step`, set `self.automatic_optimization = False` and access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(model)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m AgingGAN(config)\n\u001b[0;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(max_epochs\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:965\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[1;32m--> 965\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\strategies\\single_device.py:78\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_to_device()\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:151\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39msetup(trainer)\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n\u001b[0;32m    153\u001b[0m _optimizers_to_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_device)\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:140\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler_configs \u001b[38;5;241m=\u001b[39m \u001b[43m_init_optimizers_and_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:191\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    185\u001b[0m optimizers, lr_schedulers, monitor \u001b[38;5;241m=\u001b[39m _configure_optimizers(optim_conf)\n\u001b[0;32m    186\u001b[0m lr_scheduler_configs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    187\u001b[0m     _configure_schedulers_automatic_opt(lr_schedulers, monitor)\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _configure_schedulers_manual_opt(lr_schedulers)\n\u001b[0;32m    190\u001b[0m )\n\u001b[1;32m--> 191\u001b[0m \u001b[43m_validate_multiple_optimizers_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m _validate_optimizers_attached(optimizers, lr_scheduler_configs)\n\u001b[0;32m    193\u001b[0m _validate_scheduler_api(lr_scheduler_configs, model)\n",
      "File \u001b[1;32mc:\\Users\\ameen\\Documents\\AMRITA\\7th sem\\Project\\Code\\Fast-AgingGAN-master\\venv_name\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:350\u001b[0m, in \u001b[0;36m_validate_multiple_optimizers_support\u001b[1;34m(optimizers, model)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_multiple_optimizers_support\u001b[39m(optimizers: List[Optimizer], model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_param_in_hook_signature(model\u001b[38;5;241m.\u001b[39mtraining_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m, explicit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 350\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    351\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with multiple optimizers is only supported with manual optimization. Remove the `optimizer_idx`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    352\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m argument from `training_step`, set `self.automatic_optimization = False` and access your optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    353\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in `training_step` with `opt1, opt2, ... = self.optimizers()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    354\u001b[0m         )\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with multiple optimizers is only supported with manual optimization. Set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `self.automatic_optimization = False`, then access your optimizers in `training_step` with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `opt1, opt2, ... = self.optimizers()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Training with multiple optimizers is only supported with manual optimization. Remove the `optimizer_idx` argument from `training_step`, set `self.automatic_optimization = False` and access your optimizers in `training_step` with `opt1, opt2, ... = self.optimizers()`."
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pytorch_lightning import Trainer\n",
    "from gan_module import AgingGAN\n",
    "config_file = 'configs/aging_gan.yaml'\n",
    "\n",
    "def main():\n",
    "    with open(config_file) as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    print(config)\n",
    "    model = AgingGAN(config)\n",
    "    trainer = Trainer(max_epochs=config['epochs'])\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
